# bias_detection for textual data

### ðŸ§ª **1. [BiasCheck](https://pypi.org/project/biascheck/)**
A modular Python library designed to detect and analyze bias in text, datasets, and language models.

**Key Features:**
- Analyze standalone documents (`DocuCheck`)
- Detect bias in datasets (`SetCheck`)
- Evaluate model outputs (`ModuCheck`)
- Visualize flagged sentences and bias types
- Supports RAG pipelines and sentiment analysis [1](https://pypi.org/project/biascheck/)

---

### ðŸ§  **2. AI Fairness 360 (AIF360)**
Developed by IBM, this library provides fairness metrics and bias mitigation algorithms.

**Key Features:**
- Works with structured and unstructured data
- Includes bias detection and correction tools
- Supports integration with machine learning pipelines[2](https://github.com/topics/bias-detection)

---

### ðŸ“Š **3. WEFE (Word Embeddings Fairness Evaluation)**
A framework for measuring and mitigating bias in word embeddings.

**Key Features:**
- Standardized bias metrics (e.g., WEAT)
- Works with Word2Vec, GloVe, FastText, etc.
- Useful for NLP applications involving semantic analysis[2](https://github.com/topics/bias-detection)

---

### ðŸ§¬ **4. LangFair**
A library for assessing bias and fairness in large language models (LLMs).

**Key Features:**
- Use-case level bias evaluation
- Designed for LLMs and generative models
- Includes fairness metrics and safety checks [2](https://github.com/topics/bias-detection)

---

### ðŸ§° **5. [UnBIAS Framework](https://vectorinstitute.ai/neutralizing-bias-in-ai-vector-institutes-unbias-framework-revolutionizes-ethical-text-analysis/)**
Developed by the Vector Institute, this framework uses LLMs to detect biased content in text.

**Key Features:**
- Batch and single-text analysis
- Focus on ethical and social bias detection[3](https://vectorinstitute.ai/neutralizing-bias-in-ai-vector-institutes-unbias-framework-revolutionizes-ethical-text-analysis/)